{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://drive.google.com/uc?id=1_utx_ZGclmCwNttSe40kYA6VHzNocdET' height=\"60\"></center>\n",
        "\n",
        "AI TECH - Akademia Innowacyjnych Zastosowań Technologii Cyfrowych. Program Operacyjny Polska Cyfrowa na lata 2014-2020\n",
        "<hr>\n",
        "\n",
        "<center><img src='https://drive.google.com/uc?id=1BXZ0u3562N_MqCLcekI-Ens77Kk4LpPm'></center>\n",
        "\n",
        "<center>\n",
        "Projekt współfinansowany ze środków Unii Europejskiej w ramach Europejskiego Funduszu Rozwoju Regionalnego\n",
        "Program Operacyjny Polska Cyfrowa na lata 2014-2020,\n",
        "Oś Priorytetowa nr 3 \"Cyfrowe kompetencje społeczeństwa\" Działanie  nr 3.2 \"Innowacyjne rozwiązania na rzecz aktywizacji cyfrowej\"\n",
        "Tytuł projektu:  „Akademia Innowacyjnych Zastosowań Technologii Cyfrowych (AI Tech)”\n",
        "    </center>"
      ],
      "metadata": {
        "id": "BfdcY0Vq6e80"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcTwzhX8fBqs"
      },
      "source": [
        "Code based on https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
        "\n",
        "This exercise covers two aspects:\n",
        "* In tasks 1-6 you will implement mechanisms that allow training deeper models (better initialization, batch normalization). Note that for dropout and batch norm you are expected to implement it yourself without relying on ready-made components from Pytorch. After doing each of the tasks you can look at the plots and check how your changes impact gradients of network layers.\n",
        "* In task 7 you will implement a convnet using [conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html).\n",
        "\n",
        "\n",
        "Tasks:\n",
        "1. Check that the given implementation reaches 95% test accuracy for\n",
        "   architecture input-64-64-10 in a few thousand batches.\n",
        "2. Improve initialization and check that the network learns much faster\n",
        "   and reaches over 97% test accuracy. A good basic initialization scheme is so-called Glorot initialization. For a set of weights going from a layer with $n_{in}$ neurons to a layer with $n_{out}$ neurons, it samples each weight from normal distribution with $0$ mean and standard deviation of $\\sqrt{\\frac{2}{n_{in}+n_{out}}}$.  \n",
        "Check how better initialization changes distribution of gradients at the first epoch.\n",
        "3. Check, that with proper initialization we can train architecture\n",
        "   input-64-64-64-64-64-10, while with bad initialization it does\n",
        "   not even get off the ground.\n",
        "4. Add dropout implemented in pytorch (but without using torch.nn.Dropout)\n",
        "5. Check that with 10 hidden layers (64 units each) even with proper\n",
        "    initialization the network has a hard time to start learning.\n",
        "6. Implement batch normalization (use train mode also for testing - it should perform well enough):\n",
        "    * compute batch mean and variance\n",
        "    * add new variables beta and gamma\n",
        "    * check that the networks learns much faster for 5 layers\n",
        "    * check that the network learns even for 10 hidden layers.\n",
        "    * check how gradients change in comparison to network without batch norm.\n",
        "7. So far we worked with a fully connected network. Design and implement in pytorch (by using pytorch functions) a simple convolutional network and achieve 99% test accuracy. The architecture is up to you, but even a few convolutional layers should be enough."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYAsziKffBFV"
      },
      "source": [
        "import sys\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn import init\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    from google.colab import output\n",
        "    output.enable_custom_widget_manager()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "D2cTAah4oMkJ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# @title Visualize gradients\n",
        "\n",
        "class GradientVisualizer:\n",
        "    def __init__(self, net, num_epochs):\n",
        "        self.num_epochs = num_epochs\n",
        "        self.linear_layers = self.get_linear_layers(net)\n",
        "\n",
        "        self.grad_to_weight_fig = None\n",
        "        self.grads_in_layers_fig = None\n",
        "        self.grads_at_epochs_fig = None\n",
        "        self.init_figures()\n",
        "\n",
        "    def get_linear_layers(self, net):\n",
        "        linear_layers = []\n",
        "        for field in net.__dict__['_modules'].values():\n",
        "            if isinstance(field, Linear):\n",
        "                linear_layers.append(field)\n",
        "            if isinstance(field, nn.ModuleList):\n",
        "                for module in field:\n",
        "                    if isinstance(module, Linear):\n",
        "                        linear_layers.append(module)\n",
        "\n",
        "        assert linear_layers, \\\n",
        "        ('No linear layers found. Linear layers should be parameters of the network or they '\n",
        "        'should be placed in a ModuleList which is a parameter of the network.')\n",
        "        return linear_layers\n",
        "\n",
        "    def get_epochs_for_one_layer(self):\n",
        "        \"\"\"\n",
        "        We want to show gradient distributions from up to 7 selected epochs\n",
        "        for one linear layer.\n",
        "        \"\"\"\n",
        "        if self.num_epochs < 7:\n",
        "            return list(range(self.num_epochs))\n",
        "        else:\n",
        "            return torch.linspace(0, self.num_epochs - 1, 7).int().tolist()\n",
        "\n",
        "    def get_three_epochs(self):\n",
        "        \"\"\"\n",
        "        We want to show gradients distributions from all layers at each of\n",
        "        three epochs: first, middle and last.\n",
        "        \"\"\"\n",
        "        return [0, self.num_epochs // 2, self.num_epochs - 1]\n",
        "\n",
        "    def rgb_to_rgba(self, rgb_color, epoch):\n",
        "        \"\"\"\n",
        "        Value of epoch parameter determines how transparent color should be\n",
        "        in comparison to others.\n",
        "        Colors for earlier epochs should be more transparent/less visible.\n",
        "        \"\"\"\n",
        "        return f'rgba{rgb_color[3:-1]},{0.6 * (epoch + 1) / self.num_epochs + 0.15})'\n",
        "\n",
        "    def init_figures(self):\n",
        "        # Initialize figure with gradient to weight ratio plot\n",
        "        fig = go.Figure()\n",
        "        fig.update_layout(\n",
        "            title='Gradient standard deviation to weight standard deviation ratio', title_x=0.5,\n",
        "            xaxis_title='Epoch',\n",
        "            yaxis_title='Gradient to weight ratio (log scale)',\n",
        "            height=400, width=1500, margin=dict(b=10, t=60)\n",
        "        )\n",
        "        fig.update_yaxes(type='log')\n",
        "        for i in range(len(self.linear_layers)):\n",
        "            fig.add_trace(go.Scatter(\n",
        "                x=[], y=[],\n",
        "                mode='lines+markers', name=f'Linear layer {i}'\n",
        "            ))\n",
        "\n",
        "        self.grad_to_weight_fig = go.FigureWidget(fig)\n",
        "        display(self.grad_to_weight_fig)\n",
        "\n",
        "        # Initialize figure visualizing gradient distributions in layers\n",
        "        num_rows = (len(self.linear_layers) - 1) // 3 + 1\n",
        "        fig = make_subplots(\n",
        "            rows=num_rows, cols=3,\n",
        "            subplot_titles=[f'Linear layer {i}' for i in range(len(self.linear_layers))],\n",
        "            vertical_spacing=0.2 / num_rows\n",
        "        )\n",
        "        fig.update_layout(\n",
        "            title='Comparison between epochs of gradient distributions in layers', title_x=0.5,\n",
        "            height=num_rows * 400, width=1500, margin=dict(b=10, t=60)\n",
        "        )\n",
        "\n",
        "        colors, _ = px.colors.convert_colors_to_same_type(2 * px.colors.qualitative.Plotly)\n",
        "        for layer_num in range(len(self.linear_layers)):\n",
        "            row = layer_num // 3 + 1\n",
        "            col = layer_num % 3 + 1\n",
        "            fig.update_xaxes(\n",
        "                title_text='Gradient value', range=(-0.1, 0.1), row=row, col=col\n",
        "            )\n",
        "            fig.update_yaxes(\n",
        "                title_text='Density (log scale)', type='log', row=row, col=col\n",
        "            )\n",
        "\n",
        "            # Create empty traces and update them later with actual gradient distributions.\n",
        "            # Unfortunately, we cannot add new traces dynamically because Colab has problem\n",
        "            # with widgets from plotly (traces added dynamically are rendered twice).\n",
        "            for epoch in self.get_epochs_for_one_layer():\n",
        "                fig.add_trace(\n",
        "                    go.Scatter(\n",
        "                        mode='lines', name=f'Epoch {epoch + 1}',\n",
        "                        line=dict(color=self.rgb_to_rgba(colors[layer_num], epoch)),\n",
        "                        legendgroup=layer_num\n",
        "                    ),\n",
        "                    row=row, col=col\n",
        "                )\n",
        "\n",
        "        self.grads_in_layers_fig = go.FigureWidget(fig)\n",
        "        display(self.grads_in_layers_fig)\n",
        "\n",
        "        # Initialize figure comparing gradient distributions between layers at the\n",
        "        # first, middle and last epoch\n",
        "        selected_epochs_indices = self.get_three_epochs()\n",
        "        fig = make_subplots(\n",
        "            rows=1, cols=3,\n",
        "            subplot_titles=[f'Epoch {epoch + 1}' for epoch in selected_epochs_indices]\n",
        "        )\n",
        "        fig.update_layout(\n",
        "            title='Comparison between layers of gradient distributions at epochs', title_x=0.5,\n",
        "            height=400, width=1500, margin=dict(b=10, t=60)\n",
        "        )\n",
        "\n",
        "        for col, epoch in enumerate(selected_epochs_indices, 1):\n",
        "            fig.update_yaxes(title_text='Density (log scale)', type='log', row=1, col=col)\n",
        "            fig.update_xaxes(\n",
        "                title_text='Gradient value',\n",
        "                range=(-0.05, 0.05) if epoch != 0 else (-1, 1),\n",
        "                row=1, col=col\n",
        "            )\n",
        "\n",
        "            # Create empty traces and update them later with actual gradient distributions.\n",
        "            for layer_num in range(len(self.linear_layers)):\n",
        "                fig.append_trace(\n",
        "                    go.Scatter(\n",
        "                        mode='lines', name=f'Linear layer {layer_num}',\n",
        "                        line=dict(color=colors[layer_num]), showlegend=(col == 1)\n",
        "                    ),\n",
        "                    row=1, col=col\n",
        "                )\n",
        "\n",
        "        self.grads_at_epochs_fig = go.FigureWidget(fig)\n",
        "        display(self.grads_at_epochs_fig)\n",
        "\n",
        "    def visualize_gradients(self, lr, epoch, batch_idx):\n",
        "        # It is enough to use gradients calculated for the first batch.\n",
        "        if batch_idx != 0:\n",
        "            return\n",
        "\n",
        "        epoch_grads = []\n",
        "        epoch_grad_to_weight_ratios = []\n",
        "        for layer in self.linear_layers:\n",
        "            epoch_grads.append(layer.weight.grad.flatten().detach())\n",
        "            epoch_grad_to_weight_ratios.append(\n",
        "                (lr * layer.weight.grad.std() / layer.weight.std()).item()\n",
        "            )\n",
        "\n",
        "        # Update figure with gradient to weight ratio plot\n",
        "        for i, grad_to_weight_ratio in enumerate(epoch_grad_to_weight_ratios):\n",
        "            x = self.grad_to_weight_fig.data[i].x\n",
        "            next_x_val = x[-1] + 1 if x else 1\n",
        "            self.grad_to_weight_fig.data[i].x += (next_x_val, )\n",
        "            self.grad_to_weight_fig.data[i].y += (grad_to_weight_ratio, )\n",
        "\n",
        "        # Update figure visualizing gradient distributions in layers\n",
        "        selected_epochs = self.get_epochs_for_one_layer()\n",
        "        if epoch in selected_epochs:\n",
        "            epoch_idx = selected_epochs.index(epoch)\n",
        "            for layer_num, layer_grad in enumerate(epoch_grads):\n",
        "                trace_idx = layer_num * len(selected_epochs) + epoch_idx\n",
        "                hy, hx = torch.histogram(layer_grad, bins=50, density=True)\n",
        "                hy = hy / max(hy) + 0.001\n",
        "                self.grads_in_layers_fig.data[trace_idx].x = hx[:-1].tolist()\n",
        "                self.grads_in_layers_fig.data[trace_idx].y = hy.tolist()\n",
        "\n",
        "        # Update figure visualizing gradient distributions at epochs\n",
        "        selected_epochs = self.get_three_epochs()\n",
        "        if epoch in selected_epochs:\n",
        "            epoch_idx = selected_epochs.index(epoch)\n",
        "            for layer_num, layer_grad in enumerate(epoch_grads):\n",
        "                trace_idx = epoch_idx * len(self.linear_layers) + layer_num\n",
        "                hy, hx = torch.histogram(layer_grad, bins=50, density=True)\n",
        "                hy = hy / max(hy) + 0.001\n",
        "                self.grads_at_epochs_fig.data[trace_idx].x = hx[:-1].tolist()\n",
        "                self.grads_at_epochs_fig.data[trace_idx].y = hy.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMtap4QCfBH8"
      },
      "source": [
        "class Linear(torch.nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(Linear, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = Parameter(torch.Tensor(out_features, in_features))\n",
        "        self.bias = Parameter(torch.Tensor(out_features))\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.weight.data.normal_(mean=0,std=math.sqrt(2/(self.in_features + self.out_features))) # math.sqrt(2/(self.in_features + self.out_features))\n",
        "        init.zeros_(self.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        r = x.matmul(self.weight.t())\n",
        "        r += self.bias\n",
        "        return r\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = Linear(784, 64)\n",
        "        self.fc2 = Linear(64, 64)\n",
        "        self.fc3 = Linear(64, 64)\n",
        "        self.fc4 = Linear(64, 64)\n",
        "        self.fc5 = Linear(64, 64)\n",
        "        self.fc6 = Linear(64, 10)\n",
        "        self.dropout_probability = 0.5\n",
        "\n",
        "   def dropout(self, x, training=True):\n",
        "        if not training:  # If not in training mode, just return the input\n",
        "            return x\n",
        "        # Create a mask with the same shape as x\n",
        "        mask = (torch.rand_like(x) > self.dropout_probability).float()\n",
        "        # Scale the output by the inverse of (1 - dropout_probability)\n",
        "        return mask * x / (1 - self.dropout_probability)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc4(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc5(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc6(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgfUP23AfBMd"
      },
      "source": [
        "class MnistTrainer(object):\n",
        "    def __init__(self, batch_size):\n",
        "        transform = transforms.Compose(\n",
        "                [transforms.ToTensor()])\n",
        "        self.trainset = torchvision.datasets.MNIST(\n",
        "            root='./data',\n",
        "            download=True,\n",
        "            train=True,\n",
        "            transform=transform)\n",
        "        self.trainloader = torch.utils.data.DataLoader(\n",
        "            self.trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "        self.testset = torchvision.datasets.MNIST(\n",
        "            root='./data',\n",
        "            train=False,\n",
        "            download=True, transform=transform)\n",
        "        self.testloader = torch.utils.data.DataLoader(\n",
        "            self.testset, batch_size=1, shuffle=False, num_workers=2)\n",
        "\n",
        "    def train(self, net, gradient_visualizer, epochs=20, lr=0.05, momentum=0.9):\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            running_loss = 0.0\n",
        "            for i, data in enumerate(self.trainloader):\n",
        "                inputs, labels = data\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                outputs = net(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                gradient_visualizer.visualize_gradients(lr, epoch, i)\n",
        "                optimizer.step()\n",
        "\n",
        "                running_loss += loss.item()\n",
        "                if i % 100 == 99:\n",
        "                    print('[%d, %5d] loss: %.3f' %\n",
        "                          (epoch + 1, i + 1, running_loss / 100))\n",
        "                    running_loss = 0.0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            with torch.no_grad():\n",
        "                for data in self.testloader:\n",
        "                    images, labels = data\n",
        "                    outputs = net(images)\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "\n",
        "            print('Accuracy of the network on the {} test images: {} %'.format(\n",
        "                total, 100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "\n",
        "net = Net()\n",
        "gradient_visualizer = GradientVisualizer(net, epochs)"
      ],
      "metadata": {
        "id": "wO3ooSNUHiQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ezvIQbgsfBRT",
        "outputId": "54f47e42-c631-44ce-8c00-a670b63a3108"
      },
      "source": [
        "trainer = MnistTrainer(batch_size=128)\n",
        "trainer.train(net, gradient_visualizer, epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 53.8MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.99MB/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 13.7MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.05MB/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   100] loss: 1.066\n",
            "[1,   200] loss: 0.378\n",
            "[1,   300] loss: 0.314\n",
            "[1,   400] loss: 0.266\n",
            "Accuracy of the network on the 10000 test images: 93.44 %\n",
            "[2,   100] loss: 0.208\n",
            "[2,   200] loss: 0.205\n",
            "[2,   300] loss: 0.202\n",
            "[2,   400] loss: 0.194\n",
            "Accuracy of the network on the 10000 test images: 94.29 %\n",
            "[3,   100] loss: 0.155\n",
            "[3,   200] loss: 0.163\n",
            "[3,   300] loss: 0.158\n",
            "[3,   400] loss: 0.155\n",
            "Accuracy of the network on the 10000 test images: 95.18 %\n",
            "[4,   100] loss: 0.120\n",
            "[4,   200] loss: 0.136\n",
            "[4,   300] loss: 0.132\n",
            "[4,   400] loss: 0.135\n",
            "Accuracy of the network on the 10000 test images: 95.32 %\n",
            "[5,   100] loss: 0.127\n",
            "[5,   200] loss: 0.101\n",
            "[5,   300] loss: 0.117\n",
            "[5,   400] loss: 0.108\n",
            "Accuracy of the network on the 10000 test images: 95.66 %\n",
            "[6,   100] loss: 0.107\n",
            "[6,   200] loss: 0.101\n",
            "[6,   300] loss: 0.098\n",
            "[6,   400] loss: 0.100\n",
            "Accuracy of the network on the 10000 test images: 95.44 %\n",
            "[7,   100] loss: 0.088\n",
            "[7,   200] loss: 0.097\n",
            "[7,   300] loss: 0.098\n",
            "[7,   400] loss: 0.091\n",
            "Accuracy of the network on the 10000 test images: 95.89 %\n",
            "[8,   100] loss: 0.068\n",
            "[8,   200] loss: 0.086\n",
            "[8,   300] loss: 0.076\n",
            "[8,   400] loss: 0.093\n",
            "Accuracy of the network on the 10000 test images: 96.08 %\n",
            "[9,   100] loss: 0.067\n",
            "[9,   200] loss: 0.077\n",
            "[9,   300] loss: 0.077\n",
            "[9,   400] loss: 0.080\n",
            "Accuracy of the network on the 10000 test images: 95.95 %\n",
            "[10,   100] loss: 0.070\n",
            "[10,   200] loss: 0.065\n",
            "[10,   300] loss: 0.067\n",
            "[10,   400] loss: 0.069\n",
            "Accuracy of the network on the 10000 test images: 95.98 %\n",
            "[11,   100] loss: 0.061\n",
            "[11,   200] loss: 0.063\n",
            "[11,   300] loss: 0.061\n",
            "[11,   400] loss: 0.071\n",
            "Accuracy of the network on the 10000 test images: 96.07 %\n",
            "[12,   100] loss: 0.056\n",
            "[12,   200] loss: 0.064\n",
            "[12,   300] loss: 0.062\n",
            "[12,   400] loss: 0.067\n",
            "Accuracy of the network on the 10000 test images: 96.17 %\n",
            "[13,   100] loss: 0.044\n",
            "[13,   200] loss: 0.058\n",
            "[13,   300] loss: 0.054\n",
            "[13,   400] loss: 0.063\n",
            "Accuracy of the network on the 10000 test images: 96.12 %\n",
            "[14,   100] loss: 0.045\n",
            "[14,   200] loss: 0.053\n",
            "[14,   300] loss: 0.053\n",
            "[14,   400] loss: 0.053\n",
            "Accuracy of the network on the 10000 test images: 96.35 %\n",
            "[15,   100] loss: 0.043\n",
            "[15,   200] loss: 0.040\n",
            "[15,   300] loss: 0.047\n",
            "[15,   400] loss: 0.048\n",
            "Accuracy of the network on the 10000 test images: 96.08 %\n",
            "[16,   100] loss: 0.044\n",
            "[16,   200] loss: 0.038\n",
            "[16,   300] loss: 0.049\n",
            "[16,   400] loss: 0.043\n",
            "Accuracy of the network on the 10000 test images: 96.28 %\n",
            "[17,   100] loss: 0.042\n",
            "[17,   200] loss: 0.041\n",
            "[17,   300] loss: 0.040\n",
            "[17,   400] loss: 0.052\n",
            "Accuracy of the network on the 10000 test images: 96.32 %\n",
            "[18,   100] loss: 0.038\n",
            "[18,   200] loss: 0.045\n",
            "[18,   300] loss: 0.039\n",
            "[18,   400] loss: 0.035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQMSSwuifBTo"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX_2rCycfBWU"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}